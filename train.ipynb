{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, MaxPool2D, Conv2D, concatenate, Dropout\n",
    "from keras.layers import BatchNormalization, Flatten, InputLayer, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_attributes(inputPath):\n",
    "    cols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
    "    df = pd.read_csv(inputPath, sep=\" \",header=None, names=cols)\n",
    "    zipcodes = df[\"zipcode\"].value_counts().keys().tolist()\n",
    "    counts = df[\"zipcode\"].value_counts().tolist()\n",
    "    for (zipcode, count) in zip(zipcodes, counts):\n",
    "        if count < 25:\n",
    "            idxs = df[df[\"zipcode\"] == zipcode].index\n",
    "            df.drop(idxs, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = load_house_attributes('HousesInfo.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>area</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2520</td>\n",
       "      <td>93446</td>\n",
       "      <td>789000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1802</td>\n",
       "      <td>93446</td>\n",
       "      <td>365000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2146</td>\n",
       "      <td>93446</td>\n",
       "      <td>455000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2464</td>\n",
       "      <td>91901</td>\n",
       "      <td>599000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1845</td>\n",
       "      <td>91901</td>\n",
       "      <td>529800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1184</td>\n",
       "      <td>91901</td>\n",
       "      <td>397500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3060</td>\n",
       "      <td>91901</td>\n",
       "      <td>699999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2733</td>\n",
       "      <td>91901</td>\n",
       "      <td>689000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1706</td>\n",
       "      <td>91901</td>\n",
       "      <td>529000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4886</td>\n",
       "      <td>91901</td>\n",
       "      <td>1430000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3029</td>\n",
       "      <td>91901</td>\n",
       "      <td>825000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2620</td>\n",
       "      <td>91901</td>\n",
       "      <td>619000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2929</td>\n",
       "      <td>91901</td>\n",
       "      <td>625000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3328</td>\n",
       "      <td>91901</td>\n",
       "      <td>1095000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2250</td>\n",
       "      <td>91901</td>\n",
       "      <td>625000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2836</td>\n",
       "      <td>91901</td>\n",
       "      <td>979000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1499</td>\n",
       "      <td>91901</td>\n",
       "      <td>539000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>960</td>\n",
       "      <td>91901</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2671</td>\n",
       "      <td>91901</td>\n",
       "      <td>521500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3747</td>\n",
       "      <td>91901</td>\n",
       "      <td>925000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1675</td>\n",
       "      <td>91901</td>\n",
       "      <td>470000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3115</td>\n",
       "      <td>93446</td>\n",
       "      <td>629000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3426</td>\n",
       "      <td>91901</td>\n",
       "      <td>679000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1288</td>\n",
       "      <td>91901</td>\n",
       "      <td>549000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4042</td>\n",
       "      <td>91901</td>\n",
       "      <td>769000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>91901</td>\n",
       "      <td>245900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2726</td>\n",
       "      <td>91901</td>\n",
       "      <td>644900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>91901</td>\n",
       "      <td>895000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2445</td>\n",
       "      <td>91901</td>\n",
       "      <td>699000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1826</td>\n",
       "      <td>93446</td>\n",
       "      <td>529000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>93446</td>\n",
       "      <td>625000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1705</td>\n",
       "      <td>93446</td>\n",
       "      <td>499500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1742</td>\n",
       "      <td>93446</td>\n",
       "      <td>975000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3101</td>\n",
       "      <td>93446</td>\n",
       "      <td>895000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1056</td>\n",
       "      <td>93446</td>\n",
       "      <td>179900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1190</td>\n",
       "      <td>93446</td>\n",
       "      <td>739900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1410</td>\n",
       "      <td>93446</td>\n",
       "      <td>330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1822</td>\n",
       "      <td>93446</td>\n",
       "      <td>510000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2198</td>\n",
       "      <td>93446</td>\n",
       "      <td>625000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1088</td>\n",
       "      <td>93446</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1088</td>\n",
       "      <td>93446</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>93446</td>\n",
       "      <td>2200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1088</td>\n",
       "      <td>93446</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900</td>\n",
       "      <td>93446</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1538</td>\n",
       "      <td>93446</td>\n",
       "      <td>699500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1640</td>\n",
       "      <td>93446</td>\n",
       "      <td>425000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2108</td>\n",
       "      <td>93446</td>\n",
       "      <td>439000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>854</td>\n",
       "      <td>93446</td>\n",
       "      <td>179000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2617</td>\n",
       "      <td>93446</td>\n",
       "      <td>579500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4386</td>\n",
       "      <td>93446</td>\n",
       "      <td>759000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1570</td>\n",
       "      <td>93446</td>\n",
       "      <td>435000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1257</td>\n",
       "      <td>93446</td>\n",
       "      <td>380000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2072</td>\n",
       "      <td>93446</td>\n",
       "      <td>429900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2213</td>\n",
       "      <td>93446</td>\n",
       "      <td>585000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1500</td>\n",
       "      <td>93446</td>\n",
       "      <td>319000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>93446</td>\n",
       "      <td>1495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2330</td>\n",
       "      <td>93446</td>\n",
       "      <td>599900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1339</td>\n",
       "      <td>93446</td>\n",
       "      <td>344900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1472</td>\n",
       "      <td>93446</td>\n",
       "      <td>309995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2681</td>\n",
       "      <td>93446</td>\n",
       "      <td>572000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bedrooms  bathrooms  area  zipcode      price\n",
       "30          5        3.0  2520    93446   789000.0\n",
       "32          3        2.0  1802    93446   365000.0\n",
       "39          3        3.0  2146    93446   455000.0\n",
       "80          4        2.5  2464    91901   599000.0\n",
       "81          2        2.0  1845    91901   529800.0\n",
       "82          2        1.0  1184    91901   397500.0\n",
       "83          4        2.5  3060    91901   699999.0\n",
       "84          3        2.5  2733    91901   689000.0\n",
       "85          3        2.0  1706    91901   529000.0\n",
       "86          5        4.5  4886    91901  1430000.0\n",
       "87          4        3.5  3029    91901   825000.0\n",
       "88          4        2.5  2620    91901   619000.0\n",
       "89          7        4.0  2929    91901   625000.0\n",
       "90          4        3.5  3328    91901  1095000.0\n",
       "91          3        2.0  2250    91901   625000.0\n",
       "92          3        2.5  2836    91901   979000.0\n",
       "93          2        2.5  1499    91901   539000.0\n",
       "94          3        2.0   960    91901    65000.0\n",
       "95          3        2.0  2671    91901   521500.0\n",
       "96          5        3.0  3747    91901   925000.0\n",
       "97          3        2.5  1675    91901   470000.0\n",
       "98          4        2.5  3115    93446   629000.0\n",
       "99          4        3.5  3426    91901   679000.0\n",
       "100         3        2.0  1288    91901   549000.0\n",
       "101         4        4.0  4042    91901   769000.0\n",
       "102         2        2.0  1005    91901   245900.0\n",
       "103         4        2.5  2726    91901   644900.0\n",
       "104         3        3.0  1937    91901   895000.0\n",
       "105         3        2.5  2445    91901   699000.0\n",
       "106         3        2.0  1826    93446   529000.0\n",
       "..        ...        ...   ...      ...        ...\n",
       "474         3        2.0  1920    93446   625000.0\n",
       "475         3        2.0  1705    93446   499500.0\n",
       "476         2        2.0  1742    93446   975000.0\n",
       "477         4        3.5  3101    93446   895000.0\n",
       "478         2        2.0  1056    93446   179900.0\n",
       "479         2        2.0  1190    93446   739900.0\n",
       "480         3        2.0  1410    93446   330000.0\n",
       "481         3        2.0  1822    93446   510000.0\n",
       "482         3        2.0  2198    93446   625000.0\n",
       "483         2        2.0  1088    93446   280000.0\n",
       "484         2        2.0  1088    93446   265000.0\n",
       "485         6        5.5  5000    93446  2200000.0\n",
       "486         2        2.0  1088    93446   275000.0\n",
       "487         2        2.0   900    93446   125000.0\n",
       "488         2        2.0  1538    93446   699500.0\n",
       "489         3        2.0  1640    93446   425000.0\n",
       "490         3        2.0  2108    93446   439000.0\n",
       "491         2        1.0   854    93446   179000.0\n",
       "492         4        3.0  2617    93446   579500.0\n",
       "493         6        4.5  4386    93446   759000.0\n",
       "494         3        2.0  1570    93446   435000.0\n",
       "495         2        2.0  1257    93446   380000.0\n",
       "496         4        2.0  2072    93446   429900.0\n",
       "497         2        2.0  2213    93446   585000.0\n",
       "498         3        2.5  1500    93446   319000.0\n",
       "499         4        4.0  3000    93446  1495000.0\n",
       "500         3        2.0  2330    93446   599900.0\n",
       "501         3        2.5  1339    93446   344900.0\n",
       "502         3        2.0  1472    93446   309995.0\n",
       "503         4        4.0  2681    93446   572000.0\n",
       "\n",
       "[362 rows x 5 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in df.index.values:\n",
    "    path = os.path.sep.join(['data/', \"{}_*\".format(i+1)])\n",
    "    house_path = sorted(list(glob.glob(path)))\n",
    "    img = []\n",
    "    bath = cv2.resize(cv2.imread(house_path[0]), (224,224))\n",
    "    bed = cv2.resize(cv2.imread(house_path[1]), (224,224))\n",
    "    front = cv2.resize(cv2.imread(house_path[2]), (224,224))\n",
    "    kitchen = cv2.resize(cv2.imread(house_path[3]), (224,224))\n",
    "    \n",
    "    \n",
    "    img1 = np.concatenate((img_to_array(bath), img_to_array(bed)), axis=1)\n",
    "    img1 = img1.astype(int)\n",
    "    img2 = np.concatenate((img_to_array(front), img_to_array(kitchen)), axis=1)\n",
    "    img2 = img2.astype(int)\n",
    "    img3 = np.concatenate((img1, img2), axis=0)\n",
    "    cv2.imwrite('newdata/'+str(i)+'.jpg', img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_house_attributes(df, train, test):\n",
    "\t# initialize the column names of the continuous data\n",
    "\tcontinuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
    " \n",
    "\t# performin min-max scaling each continuous feature column to\n",
    "\t# the range [0, 1]\n",
    "\tcs = MinMaxScaler()\n",
    "\ttrainContinuous = cs.fit_transform(train[continuous])\n",
    "\ttestContinuous = cs.transform(test[continuous])\n",
    " \n",
    "\t# one-hot encode the zip code categorical data (by definition of\n",
    "\t# one-hot encoding, all output features are now in the range [0, 1])\n",
    "\tzipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
    "\ttrainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
    "\ttestCategorical = zipBinarizer.transform(test[\"zipcode\"])\n",
    " \n",
    "\t# construct our training and testing data points by concatenating\n",
    "\t# the categorical features with the continuous features\n",
    "\ttrainX = np.hstack([trainCategorical, trainContinuous])\n",
    "\ttestX = np.hstack([testCategorical, testContinuous])\n",
    " \n",
    "\t# return the concatenated training and testing data\n",
    "\treturn (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_images(df, inputPath):\n",
    "\t# initialize our images array (i.e., the house images themselves)\n",
    "\timages = []\n",
    " \n",
    "\t# loop over the indexes of the houses\n",
    "\tfor i in df.index.values:\n",
    "\t\t# find the four images for the house and sort the file paths,\n",
    "\t\t# ensuring the four are always in the *same order*\n",
    "\t\tbasePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
    "\t\thousePaths = sorted(list(glob.glob(basePath)))\n",
    "\t\t# initialize our list of input images along with the output image\n",
    "\t\t# after *combining* the four input images\n",
    "\t\tinputImages = []\n",
    "\t\toutputImage = np.zeros((64, 64, 3), dtype=\"uint8\")\n",
    " \n",
    "\t\t# loop over the input house paths\n",
    "\t\tfor housePath in housePaths:\n",
    "\t\t\t# load the input image, resize it to be 32 32, and then\n",
    "\t\t\t# update the list of input images\n",
    "\t\t\timage = cv2.imread(housePath)\n",
    "\t\t\timage = cv2.resize(image, (32, 32))\n",
    "\t\t\tinputImages.append(image)\n",
    " \n",
    "\t\t# tile the four input images in the output image such the first\n",
    "\t\t# image goes in the top-right corner, the second image in the\n",
    "\t\t# top-left corner, the third image in the bottom-right corner,\n",
    "\t\t# and the final image in the bottom-left corner\n",
    "\t\toutputImage[0:32, 0:32] = inputImages[0]\n",
    "\t\toutputImage[0:32, 32:64] = inputImages[1]\n",
    "\t\toutputImage[32:64, 32:64] = inputImages[2]\n",
    "\t\toutputImage[32:64, 0:32] = inputImages[3]\n",
    " \n",
    "\t\t# add the tiled image to our set of images the network will be\n",
    "\t\t# trained on\n",
    "\t\timages.append(outputImage)\n",
    " \n",
    "\t# return our set of images\n",
    "\treturn np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_house_images(df, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    " \n",
    "# find the largest house price in the training set and use it to\n",
    "# scale our house prices to the range [0, 1] (will lead to better\n",
    "# training and convergence)\n",
    "maxPrice = trainAttrX[\"price\"].max()\n",
    "trainY = trainAttrX[\"price\"] / maxPrice\n",
    "testY = testAttrX[\"price\"] / maxPrice\n",
    " \n",
    "# process the house attributes data by performing min-max scaling\n",
    "# on continuous features, one-hot encoding on categorical features,\n",
    "# and then finally concatenating them together\n",
    "(trainAttrX, testAttrX) = process_house_attributes(df,\n",
    "\ttrainAttrX, testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4053</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3343</td>\n",
       "      <td>36372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3923</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4022</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4116</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4581</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2544</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5524</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4229</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3550</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4829</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3428</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5462</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4021</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4406</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3721</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3710</td>\n",
       "      <td>85331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2748</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4190</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4143</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4229</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5963</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2685</td>\n",
       "      <td>85255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5677</td>\n",
       "      <td>85377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4031</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4954</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3550</td>\n",
       "      <td>85262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4180</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4464</td>\n",
       "      <td>85377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4829</td>\n",
       "      <td>85266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1471</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1248</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1214</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1882</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>987</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1606</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1554</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1717</td>\n",
       "      <td>92802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1475</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1052</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2353</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2422</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2650</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1831</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2334</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2179</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1662</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1765</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3871</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3679</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1794</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3420</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2506</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2236</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2066</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9536</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2312</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3796</td>\n",
       "      <td>94531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2      3\n",
       "0    4  4.0  4053  85255\n",
       "1    4  3.0  3343  36372\n",
       "2    3  4.0  3923  85266\n",
       "3    5  5.0  4022  85262\n",
       "4    3  4.0  4116  85266\n",
       "5    4  5.0  4581  85266\n",
       "6    3  4.0  2544  85262\n",
       "7    4  5.0  5524  85266\n",
       "8    3  4.0  4229  85255\n",
       "9    4  5.0  3550  85262\n",
       "10   5  5.0  4829  85266\n",
       "11   4  4.0  3428  85255\n",
       "12   5  3.0  5462  85266\n",
       "13   4  4.0  4021  85266\n",
       "14   5  5.0  4406  85266\n",
       "15   4  4.0  3721  85255\n",
       "16   5  3.0  3710  85331\n",
       "17   3  4.0  2748  85255\n",
       "18   5  4.0  4190  85255\n",
       "19   3  3.5  4143  85266\n",
       "20   3  3.5  4229  85255\n",
       "21   6  6.5  5963  85262\n",
       "22   3  3.0  2685  85255\n",
       "23   5  5.0  5677  85377\n",
       "24   4  4.5  4031  85262\n",
       "25   4  4.0  4954  85262\n",
       "26   4  4.5  3550  85262\n",
       "27   5  4.5  4180  85266\n",
       "28   4  4.0  4464  85377\n",
       "29   5  4.5  4829  85266\n",
       "..  ..  ...   ...    ...\n",
       "505  3  2.0  1471  92802\n",
       "506  3  2.0  1248  92802\n",
       "507  3  1.5  1214  92802\n",
       "508  4  3.0  1882  92802\n",
       "509  2  2.5   987  92802\n",
       "510  4  3.0  1606  92802\n",
       "511  3  2.5  1554  92802\n",
       "512  3  2.5  1717  92802\n",
       "513  4  2.0  1475  94531\n",
       "514  3  2.0  1052  94531\n",
       "515  4  3.0  2353  94531\n",
       "516  4  2.5  2422  94531\n",
       "517  3  2.5  2650  94531\n",
       "518  4  2.5  1831  94531\n",
       "519  4  2.0  2334  94531\n",
       "520  5  3.0  2179  94531\n",
       "521  4  2.5  1662  94531\n",
       "522  4  3.0  1765  94531\n",
       "523  3  2.0  2012  94531\n",
       "524  7  4.0  3871  94531\n",
       "525  5  3.0  3679  94531\n",
       "526  4  2.5  1794  94531\n",
       "527  4  3.5  3420  94531\n",
       "528  4  3.0  2506  94531\n",
       "529  4  2.5  2236  94531\n",
       "530  5  2.0  2066  94531\n",
       "531  4  3.5  9536  94531\n",
       "532  3  2.0  2014  94531\n",
       "533  4  3.0  2312  94531\n",
       "534  5  3.0  3796  94531\n",
       "\n",
       "[535 rows x 4 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    input_shape = (64,64,3)\n",
    "    inputs = Input(shape = input_shape)\n",
    "    x = Conv2D(32, (3,3), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(16, (3,3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs, x)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense():\n",
    "    model= Sequential()\n",
    "    model.add(Dense(16, input_shape=(trainAttrX.shape[1],), activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(8, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "den = create_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = concatenate([den.output, cnn.output])\n",
    "x = Dense(8, activation = \"relu\")(cm)\n",
    "x = Dense(1, activation = \"linear\")(x)\n",
    "model = Model(inputs = [den.input, cnn.input], outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 64)     73792       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 4, 4, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 16)     9232        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 16)     64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 2, 2, 16)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12_input (InputLayer)     (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 16)           176         dense_12_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           2080        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           544         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            264         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            9           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            17          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2)            0           dense_15[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 8)            24          concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            9           dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 181,139\n",
      "Trainable params: 180,531\n",
      "Non-trainable params: 608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 01:20:46.252931 140614612793152 deprecation_wrapper.py:118] From /home/dexter/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adam = Adam()\n",
    "model.compile(optimizer=adam, loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 271 samples, validate on 91 samples\n",
      "Epoch 1/200\n",
      "271/271 [==============================] - 11s 39ms/step - loss: 0.0181 - val_loss: 0.0039\n",
      "Epoch 2/200\n",
      "271/271 [==============================] - 4s 16ms/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 3/200\n",
      "271/271 [==============================] - 4s 16ms/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 4/200\n",
      "271/271 [==============================] - 5s 17ms/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 5/200\n",
      "271/271 [==============================] - 6s 20ms/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 6/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0045 - val_loss: 0.0020\n",
      "Epoch 7/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 8/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 9/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0053 - val_loss: 0.0016\n",
      "Epoch 10/200\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 11/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 12/200\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 13/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 14/200\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 9.7158e-04 - val_loss: 0.0015\n",
      "Epoch 15/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 17/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 18/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 19/200\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0077 - val_loss: 0.0014\n",
      "Epoch 20/200\n",
      "271/271 [==============================] - 5s 19ms/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 22/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0043 - val_loss: 9.6738e-04\n",
      "Epoch 24/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 25/200\n",
      "271/271 [==============================] - 6s 20ms/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 26/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 27/200\n",
      "271/271 [==============================] - 5s 20ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 28/200\n",
      "271/271 [==============================] - 6s 21ms/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 29/200\n",
      " 88/271 [========>.....................] - ETA: 3s - loss: 0.0014 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-019e3a9225a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit([trainAttrX,trainImagesX], trainY, \n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestImagesX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          epochs = 200, batch_size=8)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1454\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([trainAttrX,trainImagesX], trainY, \n",
    "          validation_data=([testAttrX, testImagesX], testY),\n",
    "         epochs = 200, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([testAttrX, testImagesX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    " \n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.702658325029407"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(100*(preds.flatten() - testY)/testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011628365136601895"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
